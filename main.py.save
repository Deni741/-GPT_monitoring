import os
from dotenv import load_dotenv
load_dotenv(".env.local")
from dotenv import load_dotenv
from telegram import Update, InlineKeyboardMarkup, InlineKeyboardButton
from telegram.ext import (
    ApplicationBuilder, CommandHandler, CallbackQueryHandler,
    MessageHandler, filters, ContextTypes
)
from file_manager import read_file, write_file, create_file, delete_file, list_files, edit_file
from task_handler import task_start, task_process, TASK_INPUT
# –ó–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è –∑–º—ñ–Ω–Ω–∏—Ö —Å–µ—Ä–µ–¥–æ–≤–∏—â–∞
load_dotenv()

# GPT
from openai import OpenAI
client = OpenAI(api_key=os.getenv("OPENAI_API_KEY"))

def process_gpt_query(query: str) -> str:
    try:
        response = client.chat.completions.create(
            model="gpt-4",
            messages=[{"role": "user", "content": query}],
            max_tokens=1000,
            temperature=0.7
        )
        return response.choices[0].message.content.strip()
    except Exception as e:
        return f"‚ùå –ü–æ–º–∏–ª–∫–∞ GPT: {str(e)}"

# –ö–æ–º–∞–Ω–¥–∞ —Å—Ç–∞—Ä—Ç
async def start(update: Update, context: ContextTypes.DEFAULT_TYPE):
    keyboard = [
        [InlineKeyboardButton("üìÑ Readfile", callback_data="read_file")],
        [InlineKeyboardButton("‚úèÔ∏è EditFile", callback_data="edit_file")],
        [InlineKeyboardButton("üóÇ CreateFile", callback_data="create_file")],
        [InlineKeyboardButton("üìÅ ListFiles", callback_data="list_files")],
        [InlineKeyboardButton("üöÄ PUSH", callback_data="push_code")],
        [InlineKeyboardButton("üß† GPT", callback_data="ask_gpt")]
    ]
    reply_markup = InlineKeyboardMarkup(keyboard)
    await update.message.reply_text("üîΩ –í–∏–±–µ—Ä–∏ –æ–ø—Ü—ñ—é ‚§µÔ∏è", reply_markup=reply_markup)

# /ask ‚Äî GPT –∑–∞–ø–∏—Ç
async def ask_gpt(update: Update, context: ContextTypes.DEFAULT_TYPE):
    await update.message.reply_text("ü§ñ –û–±—Ä–æ–±–∫–∞ GPT-–∑–∞–ø–∏—Ç—É...")
    query = " ".join(context.args)
    if not query:
        await update.message.reply_text("‚ùóÔ∏è–ë—É–¥—å –ª–∞—Å–∫–∞, –Ω–∞–¥—ñ—à–ª–∏ –∑–∞–ø–∏—Ç –ø—ñ—Å–ª—è –∫–æ–º–∞–Ω–¥–∏ /ask")
        return
    response = process_gpt_query(query)
    await update.message.reply_text(response[:4000])

# –û–±—Ä–æ–±–∫–∞ –∫–Ω–æ–ø–æ–∫
async def button_handler(update: Update, context: ContextTypes.DEFAULT_TYPE):
    query = update.callback_query
    await query.answer()
    data = query.data
    context.user_data["mode"] = data

    if data == "read_file":
        await query.message.reply_text("üì• –í–≤–µ–¥–∏ —à–ª—è—Ö –¥–æ —Ñ–∞–π–ª—É:")
    elif data == "edit_file":
        context.user_data["step"] = "get_filename"
        await query.message.reply_text("‚úèÔ∏è –í–≤–µ–¥–∏ –Ω–∞–∑–≤—É —Ñ–∞–π–ª—É, —è–∫–∏–π —Ö–æ—á–µ—à —Ä–µ–¥–∞–≥—É–≤–∞—Ç–∏:")
    elif data == "create_file":
        await query.message.reply_text("üìÑ –í–≤–µ–¥–∏ —à–ª—è—Ö —ñ –≤–º—ñ—Å—Ç —Ñ–∞–π–ª—É. –ü—Ä–∏–∫–ª–∞–¥:\nMemory/—Ç–µ—Å—Ç.md –¶–µ –≤–º—ñ—Å—Ç –Ω–æ–≤–æ–≥–æ —Ñ–∞–π–ª—É")
    elif data == "list_files":
        result = list_files("")
        await query.message.reply_text(result[:4000])
    elif data == "ask_gpt":
        await query.message.reply_text("üß† –í–≤–µ–¥–∏ –∑–∞–ø–∏—Ç –¥–æ GPT:")
    elif data == "push_code":
        os.system("cd /root/GPT_monitoring && git add . && git commit -m '–ê–≤—Ç–æ–æ–Ω–æ–≤–ª–µ–Ω–Ω—è GPT' && git push")
        await query.message.reply_text("‚úÖ –ö–æ–¥ –∑–∞–ø—É—à–µ–Ω–æ –Ω–∞ GitHub!")

# –û–±—Ä–æ–±–∫–∞ —Ç–µ–∫—Å—Ç–æ–≤–∏—Ö –ø–æ–≤—ñ–¥–æ–º–ª–µ–Ω—å
async def handle_message(update: Update, context: ContextTypes.DEFAULT_TYPE):
    text = update.message.text
    mode = context.user_data.get("mode", "")

    if mode == "read_file":
        result = read_file(text)
        await update.message.reply_text(result[:4000])

    elif mode == "edit_file":
        if "step" not in context.user_data:
            context.user_data["step"] = "get_filename"
            await update.message.reply_text("‚úèÔ∏è –í–≤–µ–¥–∏ –Ω–∞–∑–≤—É —Ñ–∞–π–ª—É, —è–∫–∏–π —Ö–æ—á–µ—à —Ä–µ–¥–∞–≥—É–≤–∞—Ç–∏:")
        elif context.user_data["step"] == "get_filename":
            context.user_data["filename"] = text
            context.user_data["step"] = "get_new_content"
            await update.message.reply_text("üìù –í–≤–µ–¥–∏ –Ω–æ–≤–∏–π –≤–º—ñ—Å—Ç —Ñ–∞–π–ª—É:")
        elif context.user_data["step"] == "get_new_content":
            filename = context.user_data["filename"]
            new_content = text
            result = edit_file(filename, new_content)
            await update.message.reply_text(result)
            context.user_data.clear()

    elif mode == "create_file":
        parts = text.split(maxsplit=1)
        if len(parts) < 1:
            await update.message.reply_text("‚ùóÔ∏è –ù–µ–≤—ñ—Ä–Ω–∏–π —Ñ–æ—Ä–º–∞—Ç. –ü—Ä–∏–∫–ª–∞–¥:\nMemory/—Ñ–∞–π–ª.md –ù–∞–ø–∏—Å–∞—Ç–∏ —â–æ—Å—å")
            return
        path = parts[0]
        content = parts[1] if len(parts) > 1 else ""
        result = create_file(path, content)
        await update.message.reply_text(result)

    elif mode == "ask_gpt":
        response = process_gpt_query(text)
        await update.message.reply_text(response[:4000])
from telegram.ext import ConversationHandler

TASK_INPUT = range(1)

async def task_start(update: Update, context: ContextTypes.DEFAULT_TYPE):
    await update.message.reply_text("üß† –í–≤–µ–¥–∏ –∑–∞–≤–¥–∞–Ω–Ω—è –¥–ª—è GPT:")
    return TASK_INPUT

async def task_process(update: Update, context: ContextTypes.DEFAULT_TYPE):
    user_input = update.message.text

    # –ì–µ–Ω–µ—Ä—É—î–º–æ instruction.json –Ω–∞ –æ—Å–Ω–æ–≤—ñ –∑–∞–ø–∏—Ç—É (—Ç–∏–º—á–∞—Å–æ–≤–æ –º–æ–∫)
    instruction = {
        "file_path": "Memory/task_output.md",
        "action": "create",
        "content": f"–¶–µ–π —Ñ–∞–π–ª —Å—Ç–≤–æ—Ä–µ–Ω–∏–π GPT –Ω–∞ –æ—Å–Ω–æ–≤—ñ –∑–∞–ø–∏—Ç—É:\n\n{user_input}"
    }

    with open("instruction.json", "w", encoding="utf-8") as f:
        json.dump(instruction, f, indent=2, ensure_ascii=False)

    await update.message.reply_text("üìÑ –ó–∞–¥–∞—á–∞ –ø—Ä–∏–π–Ω—è—Ç–∞. –í–∏–∫–æ–Ω—É—é...")

    result = subprocess.run(["python3", "executor.py"], capture_output=True, text=True)

    if result.returncode == 0:
        await update.message.reply_text("‚úÖ –ó–∞–≤–¥–∞–Ω–Ω—è –≤–∏–∫–æ–Ω–∞–Ω–æ —É—Å–ø—ñ—à–Ω–æ.")
    else:
        await update.message.reply_text(f"‚ùå –ü–æ–º–∏–ª–∫–∞ –≤–∏–∫–æ–Ω–∞–Ω–Ω—è:\n{result.stderr[:4000]}")

    return ConversationHandler.END

# –ó–∞–ø—É—Å–∫ –±–æ—Ç–∞
if __name__ == "__main__":
    app = ApplicationBuilder().token(os.getenv("TELEGRAM_TOKEN")).build()
    app.add_handler(CommandHandler("start", start))
    app.add_handler(CommandHandler("ask", ask_gpt))

    app.add_handler(ConversationHandler(
    entry_points=[CommandHandler("task", task_start)],
    states={TASK_INPUT: [MessageHandler(filters.TEXT & ~filters.COMMAND, task_process)]},
    fallbacks=[]
))
    app.add_handler(CallbackQueryHandler(button_handler))
    app.add_handler(MessageHandler(filters.TEXT & ~filters.COMMAND, handle_message))
    app.run_polling()
